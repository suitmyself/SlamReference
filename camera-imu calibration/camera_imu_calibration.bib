@article{Lobo2007,
abstract = {This paper proposes an approach to calibrate off-the-shelf cameras$\backslash$nand inertial sensors to have a useful integrated system to be used$\backslash$nin static and dynamic situations. When both sensors are integrated$\backslash$nin a system their relative pose needs to be determined. The rotation$\backslash$nbetween the camera and the inertial sensor can be estimated, concurrently$\backslash$nwith camera calibration, by having both sensors observe the vertical$\backslash$ndirection in several poses. The camera relies on a vertical chequered$\backslash$nplanar target and the inertial sensor on gravity to obtain a vertical$\backslash$nreference. Depending on the setup and system motion, the translation$\backslash$nbetween the two sensors can also be important. Using a simple passive$\backslash$nturntable and static images, the translation can be estimated. The$\backslash$nsystem needs to be placed in several poses and adjusted to turn about$\backslash$nthe inertial sensor centre, so that the lever arm to the camera can$\backslash$nbe determined. Simulation and real data results are presented to$\backslash$nshow the validity and simple requirements of the proposed methods.},
author = {Lobo, Jorge and Dias, Jorge},
doi = {10.1177/0278364907079276},
file = {:F$\backslash$:/reference/camera-imu calibration/2007{\_}ijrr{\_}Relative Pose Calibration Between Visual and Inertial Sensors.pdf:pdf},
isbn = {0278364907079},
issn = {02783649},
journal = {International Journal of Robotics Research},
keywords = {Calibration,Computer vision,Inertial sensors,Sensor fusion},
number = {6},
pages = {561--575},
title = {{Relative pose calibration between visual and inertial sensors}},
volume = {26},
year = {2007}
}
@article{Mirzaei2008,
abstract = {Vision-aided inertial navigation systems (V-INSs) can provide precise state estimates for the 3-D motion of a vehicle when no external references (e.g., GPS) are available. This is achieved by combining inertial measurements from an inertial measurement unit (IMU) with visual observations from a camera under the assumption that the rigid transformation between the two sensors is known. Errors in the IMU-camera extrinsic calibration process cause biases that reduce the estimation accuracy and can even lead to divergence of any estimator processing the measurements from both sensors. In this paper, we present an extended Kalman filter for precisely determining the unknown transformation between a camera and an IMU. Contrary to previous approaches, we explicitly account for the time correlation of the IMU measurements and provide a figure of merit (covariance) for the estimated transformation. The proposed method does not require any special hardware (such as spin table or 3-D laser scanner) except a calibration target. Furthermore, we employ the observability rank criterion based on Lie derivatives and prove that the nonlinear system describing the IMU-camera calibration process is observable. Simulation and experimental results are presented that validate the proposed method and quantify its accuracy.},
author = {Mirzaei, Faraz M and Roumeliotis, Stergios I},
doi = {10.1109/TRO.2008.2004486},
file = {:F$\backslash$:/reference/camera-imu calibration/2008{\_}TRO{\_}A Kalman Filter-Based Algorithm for IMU-Camera Calibration - Observability Analysis and Performance Evaluation.pdf:pdf},
isbn = {1424409128},
issn = {15523098},
journal = {IEEE Trans. Robot. },
keywords = {Extended Kalman filter,Inertial measurement unit (IMU)-camera calibration,Lie derivatives,Observability of nonlinear systems,Vision-aided inertial navigation},
number = {5},
pages = {1143--1156},
title = {{A Kalman-filter-based algorithm for IMU-camera calibration: observability analysis and performance evaluation. }},
volume = {24},
year = {2008}
}
@article{Hol2008,
abstract = {This paper is concerned with the problem of estimating the relative translation and orientation between an inertial measurement unit and a camera which are rigidly connected. The key is to realise that this problem is in fact an instance of a standard problem within the area of system identification, referred to as a gray-box problem. We propose a new algorithm for estimating the relative translation and orientation, which does not require any additional hardware, except a piece of paper with a checkerboard pattern on it. Furthermore, covariance expressions are provided for all involved estimates. The experimental results shows that the method works well in practice.},
author = {Hol, Jeroen D and Sch{\"{o}}n, Thomas B and Gustafsson, Fredrik},
doi = {10.1109/ICARCV.2008.4795810},
file = {:F$\backslash$:/reference/camera-imu calibration/2008{\_}ICARCV{\_}A New Algorithm for Calibrating a Combined Camera and IMU Sensor Unit.pdf:pdf},
isbn = {9781424422876},
journal = {2008 10th International Conference on Control, Automation, Robotics and Vision, ICARCV 2008},
keywords = {Calibration,Camera,Gray-box system identification,IMU,Kalman filter},
pages = {1857--1862},
title = {{A new algorithm for calibrating a combined camera and IMU sensor unit}},
year = {2008}
}
@article{Zachariah2010,
abstract = {An estimation procedure for calibration of a low-cost inertial measurement unit (IMU), using a rigidly mounted monocular camera, is presented. The parameters of a sensor model that captures misalignments, scale and offset errors are estimated jointly with the IMU-camera coordinate transformation parameters using a recursive Sigma-Point Kalman Filter. The method requires only a simple visual calibration pattern. A simulation study indicates the filter's ability to reach subcentimeter and subdegree accuracy.},
author = {Zachariah, D and Jansson, M},
doi = {10.1109/IPIN.2010.5646840},
file = {:F$\backslash$:/reference/camera-imu calibration/2010{\_}IPIN{\_}Joint calibration of an inertial measurement unit and coordinate transformation parameters using a monocular camera.pdf:pdf},
isbn = {VO  -},
journal = {Indoor Positioning and Indoor Navigation (IPIN), 2010 International Conference on},
keywords = {Accelerometers,Calibration,Cameras,Estimation error,Kalman filters,Mathematical model,Noise,Visualization,calibration,cameras,coordinate transformation parameter,inertial measurement unit,joint calibration,monocular camera,sigma point Kalman filter,units (measurement),visual calibration pattern},
number = {September},
pages = {1--7},
title = {{Joint calibration of an inertial measurement unit and coordinate transformation parameters using a monocular camera}},
year = {2010}
}
@article{Hol2010,
abstract = {This paper is concerned with the problem of estimating the relative translation and orientation of an inertial measurement unit and a camera, which are rigidly connected. The key is to realize that this problem is in fact an instance of a standard problem within the area of system identification, referred to as a gray-box problem. We propose a new algorithm for estimating the relative translation and orientation, which does not require any additional hardware, except a piece of paper with a checkerboard pattern on it. The method is based on a physical model which can also be used in solving, for example, sensor fusion problems. The experimental results show that the method works well in practice, both for perspective and spherical cameras},
author = {Hol, Jeroen and Sch{\"{o}}n, Thomas and Gustafsson, Fredrik},
file = {:F$\backslash$:/reference/camera-imu calibration/2010{\_}ijrr{\_}Modeling and Calibration of Inertial and Vision Sensors.pdf:pdf},
isbn = {0278364909356},
keywords = { c, inertial sensors, sensor fusion,vision sensors},
number = {29},
pages = {231--244},
title = {{Link{\"{o}}ping University Post Print Modeling and Calibration of Inertial and Vision Sensors Modeling and Calibration of Inertial and Vision Sensors}},
year = {2010}
}
@article{Fleps2011,
abstract = {Inertia-visual sensor fusion has become popular due to the complementary characteristics of cameras and IMUs. Once the spatial and temporal alignment between the sensors is known, the fusion of measurements of these devices is straightforward. Determining the alignment, however, is a challenging problem. Especially the spatial translation estimation has turned out to be difficult, mainly due to limitations of camera dynamics and noisy accelerometer measurements. Up to now, filtering-based approaches for this calibration problem are largely prevalent. However, we are not convinced that calibration, as an offline step, is necessarily a filtering issue, and we explore the benefits of interpreting it as a batch-optimization problem. To this end, we show how to model the IMU-camera calibration problem in a nonlinear optimization framework by modeling the sensors' trajectory, and we present experiments comparing this approach to filtering and system identification techniques. The results are based both on simulated and real data, showing that our approach compares favorably to conventional methods.},
author = {Fleps, Michael and Mair, Elmar and Ruepp, Oliver and Suppa, Michael and Burschka, Darius},
doi = {10.1109/IROS.2011.6048797},
file = {:F$\backslash$:/reference/camera-imu calibration/2011{\_}IROS{\_}Optimization Based IMU Camera Calibration.pdf:pdf},
isbn = {9781612844541},
issn = {2153-0858},
journal = {IEEE International Conference on Intelligent Robots and Systems},
pages = {3297--3304},
title = {{Optimization based IMU camera calibration}},
year = {2011}
}
@article{Dong-Si2012,
abstract = {This paper focuses on motion estimation using inertial measurements and observations of naturally occurring point features. To date, this task has primarily been addressed using filtering methods, which track the system state starting from known initial conditions. However, when no prior knowledge of the initial system state is available, (e.g., at the onset of the system{\&}apos;s operation), the existing approaches are not applicable. To address this problem, in this work we present algorithms for computing the system{\&}apos;s observable quantities (platform attitude and velocity, feature positions, and IMU-camera calibration) directly from the sensor measurements, without any prior knowledge. A key contribution of this work is a convex-optimization based algorithm for computing the rotation matrix between the camera and IMU. We show that once this rotation matrix has been computed, all remaining quantities can be determined by solving a quadratically constrained least-squares problem. To increase their accuracy, the initial estimates are refined by an iterative maximum-likelihood estimator. View full abstract},
author = {Dong-Si, Tue Cuong and Mourikis, Anastasios I},
doi = {10.1109/IROS.2012.6386235},
file = {:F$\backslash$:/reference/camera-imu calibration/2012{\_}IROS{\_}Estimator Initialization in Vision-aided Inertial Navigation with Unknown Camera-IMU Calibration.pdf:pdf},
isbn = {9781467317375},
issn = {21530858},
journal = {IEEE International Conference on Intelligent Robots and Systems},
pages = {1064--1071},
pmid = {6386235},
title = {{Estimator initialization in vision-aided inertial navigation with unknown camera-IMU calibration}},
year = {2012}
}
@article{Weiss2012,
author = {Weiss, Stephan and Achtelik, Markus W and Lynen, Simon and Chli, Margarita and Siegwart, Roland},
file = {:F$\backslash$:/reference/camera-imu calibration/2012{\_}ICRA{\_}Real-time Onboard Visual-Inertial State Estimation and Self-Calibration of MAVs in Unknown Environments.pdf:pdf},
isbn = {9781467314053},
pages = {957--964},
title = {{Real-time Onboard Visual-Inertial State Estimation and Self-Calibration of MAVs in Unknown Environments X ( t ) X ( t ). ilT l v ( t ) Jx ( lil ( t ) Jxfv X ( t )}},
year = {2012}
}
@article{Li2013,
author = {Li, Mingyang and Mourikis, Anastasios I},
file = {:F$\backslash$:/reference/camera-imu calibration/2013{\_}ICRA{\_}3D Motion Estimation and Online Temporal Calibration for Camera-IMU Systems.pdf:pdf},
isbn = {9781467356435},
pages = {5709--5716},
title = {{3-D motion estimation and online temporal calibration for camera-IMU systems}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6631398},
year = {2013}
}
@article{Kelly2013,
author = {Kelly, Jonathan and Sukhatme, Gaurav S},
file = {:C$\backslash$:/Users/Administrator/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kelly, Sukhatme - 2013 - SIC Codes Co p yr ig ht ss In te rn at io na l - ww w . pa.pdf:pdf},
isbn = {1220160415},
pages = {77060},
title = {{SIC Codes : Co p yr ig ht ss In te rn at io na l - ww w . pa}},
year = {2013}
}
@article{Furgale2013,
abstract = {In order to increase accuracy and robustness in state estimation for robotics, a growing number of applications rely on data from multiple complementary sensors. For the best performance in sensor fusion, these different sensors must be spatially and temporally registered with respect to each other. To this end, a number of approaches have been developed to estimate these system parameters in a two stage process, first estimating the time offset and subsequently solving for the spatial transformation between sensors. In this work, we present on a novel framework for jointly estimating the temporal offset between measurements of different sensors and their spatial displacements with respect to each other. The approach is enabled by continuous-time batch estimation and extends previous work by seamlessly incorporating time offsets within the rigorous theoretical framework of maximum likelihood estimation. Experimental results for a camera to inertial measurement unit (IMU) calibration prove the ability of this framework to accurately estimate time offsets up to a fraction of the smallest measurement period.},
author = {Furgale, Paul and Rehder, Joern and Siegwart, Roland},
doi = {10.1109/IROS.2013.6696514},
file = {:F$\backslash$:/reference/camera-imu calibration/2013{\_}IROS{\_}Unified Temporal and Spatial Calibration for Multi-Sensor Systems.pdf:pdf},
isbn = {9781467363587},
issn = {21530858},
journal = {IEEE International Conference on Intelligent Robots and Systems},
pages = {1280--1286},
title = {{Unified temporal and spatial calibration for multi-sensor systems}},
year = {2013}
}
@article{Dgpf2014,
author = {Dgpf, Der},
file = {:F$\backslash$:/reference/camera-imu calibration/2014{\_}DGPF{\_}Camera-IMU Calibration Using a Tilted Calibration Board.pdf:pdf},
pages = {1--9},
title = {{Camera-IMU Calibration Using a Tilted Calibration Board}},
year = {2014}
}
@article{Li2014,
author = {Li, M and Yu, H and Zheng, X and Mourikis, A I},
file = {:F$\backslash$:/reference/camera-imu calibration/2014{\_}ICRA{\_}High-fidelity Sensor Modeling and Self-Calibration in Vision-aided Inertial Navigation.pdf:pdf},
isbn = {9781479936854},
journal = {Proceedings of the IEEE International Conference on Robotics and Automation},
pages = {409--416},
title = {{High-fidelity sensor modeling and calibration in vision-aided inertial navigation}},
year = {2014}
}
@misc{Li2014a,
author = {Li, Mingyang and Mourikis, Anastasios I},
doi = {10.1177/0278364913515286},
file = {:F$\backslash$:/reference/camera-imu calibration/2014{\_}ijrr{\_}Online temporal calibration for camera−IMU systems - Theory and algorithms.pdf:pdf},
keywords = {identifiability analysis,online temporal calibration,time-offset estimation,vision-aided inertial navigation},
number = {i},
pages = {1--17},
title = {{Online temporal calibration for camera – IMU systems : Theory and algorithms}},
year = {2014}
}
@article{Furgale2015,
abstract = {Roboticists often formulate estimation problems in discrete time for the practical reason of keeping the state size tractable. However, the discrete-time approach does not scale well for use with high-rate sensors, such as inertial measurement units or sweeping laser imaging sensors. The difficulty lies in the fact that a pose variable is typically included for every time at which a measurement is acquired, rendering the dimension of the state impractically large for large numbers of measurements. This issue is exacerbated for the simultaneous localization and mapping (SLAM) problem, which further augments the state to include landmark variables. To address this tractability issue, we propose to move the full maximum likelihood estimation (MLE) problem into continuous time and use temporal basis functions to keep the state size manageable. We present a full probabilistic derivation of the continuous-time estimation problem, derive an estimator based on the assumption that the densities and processes involved are Gaussian, and show how coefficients of a relatively small number of basis functions can form the state to be estimated, making the solution efficient. Our derivation is presented in steps of increasingly specific assumptions, opening the door to the development of other novel continuous-time estimation algorithms through the application of different assumptions at any point. We use the SLAM problem as our motivation throughout the paper, although the approach is not specific to this application. Results from a self-calibration experiment involving a camera and a high-rate inertial measurement unit are provided to validate the approach.},
author = {Furgale, Paul and Tong, C H and Barfoot, Timothy D and Sibley, Gabe},
doi = {10.1177/0278364915585860},
file = {:F$\backslash$:/reference/camera-imu calibration/2012{\_}ICRA{\_}Continuous-Time Batch Estimation using Temporal Basis Functions.pdf:pdf},
isbn = {978-1-4673-1405-3},
issn = {0278-3649},
journal = {The International Journal of Robotics Research},
keywords = {localization,mobile and distributed robotics,sensing and perception computer,sensor fusion,slam,vision},
number = {14},
pages = {1688--1710},
title = {{Continuous-time batch trajectory estimation using temporal basis functions}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6225005{\%}5Cnhttp://ijr.sagepub.com/cgi/doi/10.1177/0278364915585860},
volume = {34},
year = {2015}
}
@article{Image2016,
author = {Image, U},
file = {:F$\backslash$:/reference/camera-imu calibration/2017{\_}SENSJ{\_}Camera-IMU Calibration Revisited.pdf:pdf},
number = {11},
pages = {1--2},
title = {{Camera IMU calibration}},
volume = {17},
year = {2016}
}
@article{Nikolic2016,
abstract = {This paper presents a solution for the extrinsic and intrinsic calibration of visual-inertial sensor systems. Calibration is formulated as a joint state and parameter estimation problem of a continuous-time system with discrete-time measurements. A maximum-likelihood estimator is derived to estimate the transform between cameras and inertial sensors, temporal alignment, and inertial sensor intrinsic parameters, such as scale factors, axes misalignment, and sensor noise characteristics. The estimator is simple to implement, consistent, and asymptotically attains the Cram{\'{e}}r-Rao lower bound. In contrast to the existing methods, it requires no tuning parameters. Detailed results from repeated calibration experiments with a camera-inertial measurement unit system are reported and compared with the results obtained from a modern, parametric method. We reach a precision of {\textless}1 mm in extrinsic translation, 1 mrad in orientation, and 10 {\$}\mu{\$}text{\{}s{\}} in time shift—within a calibration window of 20 s.},
author = {Nikolic, Janosch and Burri, Michael and Gilitschenski, Igor and Nieto, Juan and Siegwart, Roland},
doi = {10.1109/JSEN.2016.2556662},
file = {:F$\backslash$:/reference/camera-imu calibration/2016{\_}SENSJ{\_}Non-Parametric Extrinsic and Intrinsic Calibration of Visual-Inertial Sensor Systems.pdf:pdf},
issn = {1530437X},
journal = {IEEE Sensors Journal},
keywords = {Calibration,cameras,inertial measurement units,maximum likelihood},
number = {13},
pages = {5433--5443},
title = {{Non-Parametric Extrinsic and Intrinsic Calibration of Visual-Inertial Sensor Systems}},
volume = {16},
year = {2016}
}
